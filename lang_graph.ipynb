{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgEbcfeYjbCYP5sE3ko9O8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhatsbharath/generative_ai_agents/blob/main/lang_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9e902vn1Xnv"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "\n",
        "llm = ChatOllama(\n",
        "\tmodel=\"llama3.2\",\n",
        "\ttemperature=0.7,\n",
        "\ttop_p=0.9,\n",
        "\tnum_predict=256,\n",
        "\trepeat_penalty=1.1\n",
        ")\n",
        "response = llm.invoke(\"Hello!\")\n",
        "print(response.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import TypedDict, List, Annotated\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "from IPython.display import display, Image"
      ],
      "metadata": {
        "id": "weh5RzNd150_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    text: str\n",
        "    classification: str\n",
        "    entities: List[str]\n",
        "    summary: str\n",
        "\n",
        "# Initialize our language model with temperature=0 for more deterministic outputs\n",
        "llm = ChatOllama(\n",
        "\tmodel=\"llama3.2\",\n",
        "\ttemperature=0.7,\n",
        "\ttop_p=0.9,\n",
        "\tnum_predict=256,\n",
        "\trepeat_penalty=1.1\n",
        ")"
      ],
      "metadata": {
        "id": "GiKI21Mk19CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_node(state: State):\n",
        "    '''Classify the text into one of the categories: News, Blog, Research, or Other'''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Classify the following text into one of the categories: News, Blog, Research, or Other.\\n\\nText:{text}\\n\\nCategory:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    classification = llm.invoke([message]).content.strip()\n",
        "    return {\"classification\": classification}"
      ],
      "metadata": {
        "id": "zTFjcb6J1-V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entity_extraction_node(state: State):\n",
        "    '''Extract all the entities (Person, Organization, Location) from the text'''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Extract all the entities (Person, Organization, Location) from the following text. Provide the result as a comma-separated list.\\n\\nText:{text}\\n\\nEntities:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    entities = llm.invoke([message]).content.strip().split(\", \")\n",
        "    return {\"entities\": entities}"
      ],
      "metadata": {
        "id": "ntc3W9Ha1_bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarization_node(state: State):\n",
        "    '''Summarize the text in one short sentence'''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Summarize the following text in one short sentence.\\n\\nText:{text}\\n\\nSummary:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    summary = llm.invoke([message]).content.strip()\n",
        "    return {\"summary\": summary}"
      ],
      "metadata": {
        "id": "2cBElxbG2Abv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our StateGraph\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"classification_node\", classification_node)\n",
        "workflow.add_node(\"entity_extraction\", entity_extraction_node)\n",
        "workflow.add_node(\"summarization\", summarization_node)\n",
        "\n",
        "# Add edges to the graph\n",
        "workflow.set_entry_point(\"classification_node\")  # Set the entry point of the graph\n",
        "workflow.add_edge(\"classification_node\", \"entity_extraction\")\n",
        "workflow.add_edge(\"entity_extraction\", \"summarization\")\n",
        "workflow.add_edge(\"summarization\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "_b3TsRFH2Bwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a visualization of our graph\n",
        "try:\n",
        "    display(\n",
        "        Image(\n",
        "            app.get_graph().draw_mermaid_png(\n",
        "                draw_method=MermaidDrawMethod.API,\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Error generating visualization: {e}\")\n",
        "    print(\"The graph structure is: classification_node -> entity_extraction -> summarization -> END\")"
      ],
      "metadata": {
        "id": "1M4Vc2bq2KZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"\n",
        "Ban on mobile phones in office.\n",
        "\"\"\"\n",
        "\n",
        "state_input = {\"text\": sample_text}\n",
        "result = app.invoke(state_input)\n",
        "\n",
        "print(\"Classification:\", result[\"classification\"])\n",
        "print(\"\\nEntities:\", result[\"entities\"])\n",
        "print(\"\\nSummary:\", result[\"summary\"])"
      ],
      "metadata": {
        "id": "zS8uSpbU2Mt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace this with your own text to analyze\n",
        "your_text = \"\"\"\n",
        "The recent advancements in quantum computing have opened new possibilities for cryptography and data security.\n",
        "Researchers at MIT and Google have demonstrated quantum algorithms that could potentially break current encryption methods.\n",
        "However, they are also developing new quantum-resistant encryption techniques to protect data in the future.\n",
        "\"\"\"\n",
        "\n",
        "# Process the text through our pipeline\n",
        "your_result = app.invoke({\"text\": your_text})\n",
        "\n",
        "print(\"Classification:\", your_result[\"classification\"])\n",
        "print(\"\\nEntities:\", your_result[\"entities\"])\n",
        "print(\"\\nSummary:\", your_result[\"summary\"])"
      ],
      "metadata": {
        "id": "RbwS19w-2O_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's update our State to include sentiment\n",
        "class EnhancedState(TypedDict):\n",
        "    text: str\n",
        "    classification: str\n",
        "    entities: List[str]\n",
        "    summary: str\n",
        "    sentiment: str\n",
        "\n",
        "# Create our sentiment analysis node\n",
        "def sentiment_node(state: EnhancedState):\n",
        "    '''Analyze the sentiment of the text: Positive, Negative, or Neutral'''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Analyze the sentiment of the following text. Is it Positive, Negative, or Neutral?\\n\\nText:{text}\\n\\nSentiment:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    sentiment = llm.invoke([message]).content.strip()\n",
        "    return {\"sentiment\": sentiment}\n",
        "\n",
        "# Create a new workflow with the enhanced state\n",
        "enhanced_workflow = StateGraph(EnhancedState)\n",
        "\n",
        "# Add the existing nodes\n",
        "enhanced_workflow.add_node(\"classification_node\", classification_node)\n",
        "enhanced_workflow.add_node(\"entity_extraction\", entity_extraction_node)\n",
        "enhanced_workflow.add_node(\"summarization\", summarization_node)\n",
        "\n",
        "# Add our new sentiment node\n",
        "enhanced_workflow.add_node(\"sentiment_analysis\", sentiment_node)\n",
        "\n",
        "# Create a more complex workflow with branches\n",
        "enhanced_workflow.set_entry_point(\"classification_node\")\n",
        "enhanced_workflow.add_edge(\"classification_node\", \"entity_extraction\")\n",
        "enhanced_workflow.add_edge(\"entity_extraction\", \"summarization\")\n",
        "enhanced_workflow.add_edge(\"summarization\", \"sentiment_analysis\")\n",
        "enhanced_workflow.add_edge(\"sentiment_analysis\", END)\n",
        "\n",
        "# Compile the enhanced graph\n",
        "enhanced_app = enhanced_workflow.compile()"
      ],
      "metadata": {
        "id": "SLzioQVd2QfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try the enhanced pipeline with the same text\n",
        "enhanced_result = enhanced_app.invoke({\"text\": sample_text})\n",
        "\n",
        "print(\"Classification:\", enhanced_result[\"classification\"])\n",
        "print(\"\\nEntities:\", enhanced_result[\"entities\"])\n",
        "print(\"\\nSummary:\", enhanced_result[\"summary\"])\n",
        "print(\"\\nSentiment:\", enhanced_result[\"sentiment\"])"
      ],
      "metadata": {
        "id": "vyBqCCkH2Rnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedState(TypedDict):\n",
        "    text: str\n",
        "    classification: str\n",
        "    entities: List[str]\n",
        "    summary: str\n",
        "    sentiment: str"
      ],
      "metadata": {
        "id": "QYESMyjX2SoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Route after classification\n",
        "def route_after_classification(state: EnhancedState) -> str:\n",
        "    category = state[\"classification\"].lower() # returns: \"news\", \"blog\", \"research\", \"other\"\n",
        "    return category in [\"news\", \"research\"]"
      ],
      "metadata": {
        "id": "ZiN5rrgf2Ydv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "conditional_workflow = StateGraph(EnhancedState)\n",
        "\n",
        "# Add nodes\n",
        "conditional_workflow.add_node(\"classification_node\", classification_node)\n",
        "conditional_workflow.add_node(\"entity_extraction\", entity_extraction_node)\n",
        "conditional_workflow.add_node(\"summarization\", summarization_node)\n",
        "conditional_workflow.add_node(\"sentiment_analysis\", sentiment_node)\n",
        "\n",
        "# Set entry point\n",
        "conditional_workflow.set_entry_point(\"classification_node\")\n",
        "\n",
        "# Add conditional edge\n",
        "conditional_workflow.add_conditional_edges(\"classification_node\", route_after_classification, path_map={\n",
        "    True: \"entity_extraction\",\n",
        "    False: \"summarization\"\n",
        "})\n",
        "\n",
        "# Add remaining static edges\n",
        "conditional_workflow.add_edge(\"entity_extraction\", \"summarization\")\n",
        "conditional_workflow.add_edge(\"summarization\", \"sentiment_analysis\")\n",
        "conditional_workflow.add_edge(\"sentiment_analysis\", END)\n",
        "\n",
        "# Compile\n",
        "conditional_app = conditional_workflow.compile()"
      ],
      "metadata": {
        "id": "xA5_lZsL2Zq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(\n",
        "        conditional_app.get_graph().draw_mermaid_png()\n",
        "    ))\n",
        "except:\n",
        "    print(\"Graph: classification_node → (conditional) → [entity_extraction or summarization] → sentiment_analysis → END\")"
      ],
      "metadata": {
        "id": "44GBQOeg2bFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"\"\"\n",
        "OpenAI released the GPT-4 model with enhanced performance on academic and professional tasks. It's seen as a major breakthrough in alignment and reasoning capabilities.\n",
        "\"\"\"\n",
        "\n",
        "result = conditional_app.invoke({\"text\": test_text})\n",
        "\n",
        "print(\"Classification:\", result[\"classification\"])\n",
        "print(\"Entities:\", result.get(\"entities\", \"Skipped\"))\n",
        "print(\"Summary:\", result[\"summary\"])\n",
        "print(\"Sentiment:\", result[\"sentiment\"])"
      ],
      "metadata": {
        "id": "uwBVfFAu2cY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blog_text = \"\"\"\n",
        "Here's what I learned from a week of meditating in silence. No phones, no talking—just me, my breath, and some deep realizations.\n",
        "\"\"\"\n",
        "\n",
        "result = conditional_app.invoke({\"text\": blog_text})\n",
        "\n",
        "print(\"Classification:\", result[\"classification\"])\n",
        "print(\"Entities:\", result.get(\"entities\", \"Skipped (not applicable)\"))\n",
        "print(\"Summary:\", result[\"summary\"])\n",
        "print(\"Sentiment:\", result[\"sentiment\"])"
      ],
      "metadata": {
        "id": "rAPkoy0q2dhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a0Wj2-bU2ex3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}