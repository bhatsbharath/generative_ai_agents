{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhatsbharath/generative_ai_agents/blob/main/lang_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraph\n",
        "LangGraph is a powerful framework by LangChain designed for creating stateful, multi-actor applications with LLMs. It provides the structure and tools needed to build sophisticated AI agents through a graph-based approach."
      ],
      "metadata": {
        "id": "jdRGkiGjodjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import TypedDict, List, Annotated\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "from IPython.display import display, Image"
      ],
      "metadata": {
        "id": "weh5RzNd150_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines a State class using TypedDict to structure data with text, classification, entities, and summary.\n",
        "Just as human intelligence requires memory, our agent needs a way to keep track of information. We create this using a TypedDict to define our state structure:\n",
        "\n",
        "Initializes a ChatOllama model with specified parameters (temperature, top-p, etc.) for generating more controlled outputs."
      ],
      "metadata": {
        "id": "lyuLbw5QpABC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    text: str\n",
        "    classification: str\n",
        "    entities: List[str]\n",
        "    summary: str\n",
        "\n",
        "# Initialize our language model with temperature=0 for more deterministic outputs\n",
        "llm = ChatOllama(\n",
        "\tmodel=\"llama3.2\",\n",
        "\ttemperature=0.7,\n",
        "\ttop_p=0.9,\n",
        "\tnum_predict=256,\n",
        "\trepeat_penalty=1.1\n",
        ")"
      ],
      "metadata": {
        "id": "GiKI21Mk19CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines classification_node to classify text into one of four categories: News, Blog, Research, or Other.\n",
        "\n",
        "Uses a PromptTemplate to format the text and sends it to the ChatOllama model for classification"
      ],
      "metadata": {
        "id": "OpCDivtqpcX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_node(state: State):\n",
        "    '''Classify the text into one of the categories: News, Blog, Research, or Other'''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Classify the following text into one of the categories: News, Blog, Research, or Other.\\n\\nText:{text}\\n\\nCategory:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    classification = llm.invoke([message]).content.strip()\n",
        "    return {\"classification\": classification}"
      ],
      "metadata": {
        "id": "zTFjcb6J1-V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines entity_extraction_node to extract entities (Person, Organization, Location) from the text.\n",
        "\n",
        "Uses a PromptTemplate to format the text and sends it to the ChatOllama model to extract and return the entities as a comma-separated list."
      ],
      "metadata": {
        "id": "cixKXAkZpfn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entity_extraction_node(state: State):\n",
        "    '''Extract all the entities (Person, Organization, Location) from the text'''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Extract all the entities (Person, Organization, Location) from the following text. Provide the result as a comma-separated list.\\n\\nText:{text}\\n\\nEntities:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    entities = llm.invoke([message]).content.strip().split(\", \")\n",
        "    return {\"entities\": entities}"
      ],
      "metadata": {
        "id": "ntc3W9Ha1_bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines summarization_node to generate a one-sentence summary of the input text.\n",
        "\n",
        "Uses a PromptTemplate to format the text and sends it to the ChatOllama model for summarization."
      ],
      "metadata": {
        "id": "1lE6qs9CpjIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarization_node(state: State):\n",
        "    '''Summarize the text in one short sentence'''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Summarize the following text in one short sentence.\\n\\nText:{text}\\n\\nSummary:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    summary = llm.invoke([message]).content.strip()\n",
        "    return {\"summary\": summary}"
      ],
      "metadata": {
        "id": "2cBElxbG2Abv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates a StateGraph workflow and adds nodes for classification, entity extraction, and summarization.\n",
        "\n",
        "Defines the flow of the graph with edges, starting from classification_node and ending at summarization.\n",
        "\n",
        "Compiles the graph into an executable application."
      ],
      "metadata": {
        "id": "UTGu00zVpmXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our StateGraph\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"classification_node\", classification_node)\n",
        "workflow.add_node(\"entity_extraction\", entity_extraction_node)\n",
        "workflow.add_node(\"summarization\", summarization_node)\n",
        "\n",
        "# Add edges to the graph\n",
        "workflow.set_entry_point(\"classification_node\")  # Set the entry point of the graph\n",
        "workflow.add_edge(\"classification_node\", \"entity_extraction\")\n",
        "workflow.add_edge(\"entity_extraction\", \"summarization\")\n",
        "workflow.add_edge(\"summarization\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "_b3TsRFH2Bwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempts to generate and display a visualization of the workflow graph using the draw_mermaid_png method.\n",
        "\n",
        "If an error occurs, prints the graph structure as a fallback."
      ],
      "metadata": {
        "id": "aJ6P4FWCppf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a visualization of our graph\n",
        "try:\n",
        "    display(\n",
        "        Image(\n",
        "            app.get_graph().draw_mermaid_png(\n",
        "                draw_method=MermaidDrawMethod.API,\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Error generating visualization: {e}\")\n",
        "    print(\"The graph structure is: classification_node -> entity_extraction -> summarization -> END\")"
      ],
      "metadata": {
        "id": "1M4Vc2bq2KZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"\n",
        "Ban on mobile phones in office.\n",
        "\"\"\"\n",
        "\n",
        "state_input = {\"text\": sample_text}\n",
        "result = app.invoke(state_input)\n",
        "\n",
        "print(\"Classification:\", result[\"classification\"])\n",
        "print(\"\\nEntities:\", result[\"entities\"])\n",
        "print(\"\\nSummary:\", result[\"summary\"])"
      ],
      "metadata": {
        "id": "zS8uSpbU2Mt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace this with your own text to analyze\n",
        "your_text = \"\"\"\n",
        "The recent advancements in quantum computing have opened new possibilities for cryptography and data security.\n",
        "Researchers at MIT and Google have demonstrated quantum algorithms that could potentially break current encryption methods.\n",
        "However, they are also developing new quantum-resistant encryption techniques to protect data in the future.\n",
        "\"\"\"\n",
        "\n",
        "# Process the text through our pipeline\n",
        "your_result = app.invoke({\"text\": your_text})\n",
        "\n",
        "print(\"Classification:\", your_result[\"classification\"])\n",
        "print(\"\\nEntities:\", your_result[\"entities\"])\n",
        "print(\"\\nSummary:\", your_result[\"summary\"])"
      ],
      "metadata": {
        "id": "RbwS19w-2O_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional Edge in LangGraph"
      ],
      "metadata": {
        "id": "dmeISgkLHXR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extends the State to include a new sentiment field in EnhancedState.\n",
        "\n",
        "Creates a sentiment_node to analyze the sentiment of the text (Positive, Negative, or Neutral).\n",
        "\n",
        "Updates the workflow to include the new sentiment analysis node and defines a more complex flow.\n",
        "\n",
        "Compiles the enhanced graph with the updated nodes and edges."
      ],
      "metadata": {
        "id": "wCm_NYRepyK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's update our State to include sentiment\n",
        "class EnhancedState(TypedDict):\n",
        "    text: str\n",
        "    classification: str\n",
        "    entities: List[str]\n",
        "    summary: str\n",
        "    sentiment: str\n",
        "\n",
        "# Create our sentiment analysis node\n",
        "def sentiment_node(state: EnhancedState):\n",
        "    '''Analyze the sentiment of the text: Positive, Negative, or Neutral'''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Analyze the sentiment of the following text. Is it Positive, Negative, or Neutral?\\n\\nText:{text}\\n\\nSentiment:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    sentiment = llm.invoke([message]).content.strip()\n",
        "    return {\"sentiment\": sentiment}\n",
        "\n",
        "# Create a new workflow with the enhanced state\n",
        "enhanced_workflow = StateGraph(EnhancedState)\n",
        "\n",
        "# Add the existing nodes\n",
        "enhanced_workflow.add_node(\"classification_node\", classification_node)\n",
        "enhanced_workflow.add_node(\"entity_extraction\", entity_extraction_node)\n",
        "enhanced_workflow.add_node(\"summarization\", summarization_node)\n",
        "\n",
        "# Add our new sentiment node\n",
        "enhanced_workflow.add_node(\"sentiment_analysis\", sentiment_node)\n",
        "\n",
        "# Create a more complex workflow with branches\n",
        "enhanced_workflow.set_entry_point(\"classification_node\")\n",
        "enhanced_workflow.add_edge(\"classification_node\", \"entity_extraction\")\n",
        "enhanced_workflow.add_edge(\"entity_extraction\", \"summarization\")\n",
        "enhanced_workflow.add_edge(\"summarization\", \"sentiment_analysis\")\n",
        "enhanced_workflow.add_edge(\"sentiment_analysis\", END)\n",
        "\n",
        "# Compile the enhanced graph\n",
        "enhanced_app = enhanced_workflow.compile()"
      ],
      "metadata": {
        "id": "SLzioQVd2QfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try the enhanced pipeline with the same text\n",
        "enhanced_result = enhanced_app.invoke({\"text\": sample_text})\n",
        "\n",
        "print(\"Classification:\", enhanced_result[\"classification\"])\n",
        "print(\"\\nEntities:\", enhanced_result[\"entities\"])\n",
        "print(\"\\nSummary:\", enhanced_result[\"summary\"])\n",
        "print(\"\\nSentiment:\", enhanced_result[\"sentiment\"])"
      ],
      "metadata": {
        "id": "vyBqCCkH2Rnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedState(TypedDict):\n",
        "    text: str\n",
        "    classification: str\n",
        "    entities: List[str]\n",
        "    summary: str\n",
        "    sentiment: str"
      ],
      "metadata": {
        "id": "QYESMyjX2SoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines a routing function to determine the next step based on the classification (News, Blog, Research, or Other).\n",
        "\n",
        "Returns True if the classification is \"news\" or \"research\", and False otherwise."
      ],
      "metadata": {
        "id": "UkXepbAeqHNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Route after classification\n",
        "def route_after_classification(state: EnhancedState) -> str:\n",
        "    category = state[\"classification\"].lower() # returns: \"news\", \"blog\", \"research\", \"other\"\n",
        "    return category in [\"news\", \"research\"]"
      ],
      "metadata": {
        "id": "ZiN5rrgf2Ydv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates a conditional workflow using StateGraph, where the path depends on the result of route_after_classification.\n",
        "\n",
        "Adds nodes for classification, entity extraction, summarization, and sentiment analysis.\n",
        "\n",
        "Routes based on classification: if \"news\" or \"research\", continue to entity extraction; otherwise, go to summarization.\n",
        "\n",
        "Compiles the graph with both conditional and static edges."
      ],
      "metadata": {
        "id": "8kyCaiDyqLup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "conditional_workflow = StateGraph(EnhancedState)\n",
        "\n",
        "# Add nodes\n",
        "conditional_workflow.add_node(\"classification_node\", classification_node)\n",
        "conditional_workflow.add_node(\"entity_extraction\", entity_extraction_node)\n",
        "conditional_workflow.add_node(\"summarization\", summarization_node)\n",
        "conditional_workflow.add_node(\"sentiment_analysis\", sentiment_node)\n",
        "\n",
        "# Set entry point\n",
        "conditional_workflow.set_entry_point(\"classification_node\")\n",
        "\n",
        "# Add conditional edge\n",
        "conditional_workflow.add_conditional_edges(\"classification_node\", route_after_classification, path_map={\n",
        "    True: \"entity_extraction\",\n",
        "    False: \"summarization\"\n",
        "})\n",
        "\n",
        "# Add remaining static edges\n",
        "conditional_workflow.add_edge(\"entity_extraction\", \"summarization\")\n",
        "conditional_workflow.add_edge(\"summarization\", \"sentiment_analysis\")\n",
        "conditional_workflow.add_edge(\"sentiment_analysis\", END)\n",
        "\n",
        "# Compile\n",
        "conditional_app = conditional_workflow.compile()"
      ],
      "metadata": {
        "id": "xA5_lZsL2Zq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(\n",
        "        conditional_app.get_graph().draw_mermaid_png()\n",
        "    ))\n",
        "except:\n",
        "    print(\"Graph: classification_node → (conditional) → [entity_extraction or summarization] → sentiment_analysis → END\")"
      ],
      "metadata": {
        "id": "44GBQOeg2bFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines a test_text sample.\n",
        "\n",
        "Invokes the conditional_app workflow with the text, triggering classification, entity extraction, summarization, and sentiment analysis.\n",
        "\n",
        "Prints the results of the classification, entities, summary, and sentiment analysis."
      ],
      "metadata": {
        "id": "o0Jcd5LCqQY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"\"\"\n",
        "OpenAI released the GPT-4 model with enhanced performance on academic and professional tasks. It's seen as a major breakthrough in alignment and reasoning capabilities.\n",
        "\"\"\"\n",
        "\n",
        "result = conditional_app.invoke({\"text\": test_text})\n",
        "\n",
        "print(\"Classification:\", result[\"classification\"])\n",
        "print(\"Entities:\", result.get(\"entities\", \"Skipped\"))\n",
        "print(\"Summary:\", result[\"summary\"])\n",
        "print(\"Sentiment:\", result[\"sentiment\"])"
      ],
      "metadata": {
        "id": "uwBVfFAu2cY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blog_text = \"\"\"\n",
        "Here's what I learned from a week of meditating in silence. No phones, no talking—just me, my breath, and some deep realizations.\n",
        "\"\"\"\n",
        "\n",
        "result = conditional_app.invoke({\"text\": blog_text})\n",
        "\n",
        "print(\"Classification:\", result[\"classification\"])\n",
        "print(\"Entities:\", result.get(\"entities\", \"Skipped (not applicable)\"))\n",
        "print(\"Summary:\", result[\"summary\"])\n",
        "print(\"Sentiment:\", result[\"sentiment\"])"
      ],
      "metadata": {
        "id": "rAPkoy0q2dhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a0Wj2-bU2ex3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}